{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "import datasist as ds\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#load datasets\n",
    "traindemographics = pd.read_csv('data/traindemographics.csv', parse_dates=['birthdate'])\n",
    "testdemographics = pd.read_csv('data/testdemographics.csv', parse_dates=['birthdate'])\n",
    "trainperf = pd.read_csv('data/trainperf.csv', parse_dates=['approveddate','creationdate'])\n",
    "testperf = pd.read_csv('data/testperf.csv',parse_dates=['approveddate','creationdate'])\n",
    "trainprevloans= pd.read_csv('data/trainprevloans.csv', parse_dates=['approveddate','creationdate','closeddate','firstduedate','firstrepaiddate'])\n",
    "testprevloans = pd.read_csv('data/testprevloans.csv', parse_dates=['approveddate','creationdate','closeddate','firstduedate','firstrepaiddate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8ef6507d29a16e8fdc448032aada08f5a930a5c6"
   },
   "outputs": [],
   "source": [
    "#Print the size and shape of the data\n",
    "print('traindemographics shape:', traindemographics.shape)\n",
    "print('testdemographics shape:', testdemographics.shape)\n",
    "print('trainperf shape:', trainperf.shape)\n",
    "print('testperf shape:', testperf.shape)\n",
    "print('trainprevloans shape:', trainprevloans.shape)\n",
    "print('testprevloans shape:', testprevloans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c69642b7522bf8d4996579825aa51a1e19f322c8"
   },
   "source": [
    "Let's preview all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f16bc98e1aad5db64a2f4423a37e5b2d33c10ee7"
   },
   "outputs": [],
   "source": [
    "traindemographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6f878535756cd8a5b46a8395be63556b061b94c"
   },
   "outputs": [],
   "source": [
    "testdemographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fcf4073701559be366ee0b8ab8601de56420ac1a"
   },
   "outputs": [],
   "source": [
    "trainperf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43ff871be9eb012e2ee728283cdc9a195c31e799"
   },
   "outputs": [],
   "source": [
    "testperf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7757610d00ffa3d391b29ffbbc6813bc40e4ed39"
   },
   "outputs": [],
   "source": [
    "trainprevloans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5249bb526b9d4aa19d982f987aa121dff4ef61f4"
   },
   "outputs": [],
   "source": [
    "testprevloans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29b156fa923163f5ad8d7fbc90dcebf11fb1d89b"
   },
   "source": [
    "Let's explore our data and create a base line model.\n",
    "We'll start with the main train data **trainperf** do some feature engineering and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4bc76a5f07c1e71fd4835b5e499f2a7f0ff679e0"
   },
   "outputs": [],
   "source": [
    "trainperf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a13625bb44229b54e352a20321c3776781c40b3"
   },
   "outputs": [],
   "source": [
    "def process_perf_data(df, dataset='train', to_categorical=True):\n",
    "    #drop systemloanid and loannumber\n",
    "    proc_df = df.copy()\n",
    "    #get the interest to be paid on the loan\n",
    "    proc_df['interest'] = proc_df['totaldue'] - proc_df['loanamount']\n",
    "    \n",
    "    # Convert days to year by dividing with 365)\n",
    "    proc_df['termyears'] = proc_df['termdays'] / 365\n",
    "    #Drop original days column\n",
    "    proc_df.drop(['termdays'], axis=1, inplace=True)\n",
    "    #get the rate of interest R = I/P*T \n",
    "    proc_df['rateofinterest'] = proc_df['interest'] / (proc_df['loanamount'] * proc_df['termyears'])\n",
    "    \n",
    "    #Convert referredby to a boolean column of yes and no\n",
    "    #First, get the null values index\n",
    "    indx_null = proc_df[proc_df['referredby'].isnull()].index\n",
    "    # Get the index of not null values\n",
    "    indx_not_null = proc_df[~proc_df['referredby'].isnull()].index\n",
    "    proc_df['referredbysomeone'] = proc_df['referredby']\n",
    "    proc_df['referredbysomeone'][indx_null] = False\n",
    "    proc_df['referredbysomeone'][indx_not_null] = True\n",
    "    #Drop referredby column\n",
    "    proc_df.drop(['referredby'], axis=1, inplace=True)\n",
    "    \n",
    "    #Get some information from approveddate and creationdate columns\n",
    "    #First create dictionary keys for dayofweek and month of year\n",
    "    dic_dayofweek = {0:'mon',1:'tue',2:'wed',3:'thur',4:'fri',5:'sat',6:'sun'}\n",
    "    dic_month = {1:'jan', 2:'feb',3:'mar',4:'apr',5:'may',6:'jun',7:'jul',8:'aug', 9:'sept',10:'oct',11:'nov',12:'dec'}\n",
    "    \n",
    "#     #Convert to categorical if processing trainperf\n",
    "#     if to_categorical:\n",
    "#         proc_df['approveddayofweek'] = proc_df['approveddate'].dt.dayofweek.map(dic_dayofweek)\n",
    "#         proc_df['approvedmonth'] = proc_df['approveddate'].dt.month.map(dic_month)\n",
    "#         proc_df['creationdayofweek'] = proc_df['creationdate'].dt.dayofweek.map(dic_dayofweek)\n",
    "#         proc_df['creationmonth'] = proc_df['creationdate'].dt.month.map(dic_month)\n",
    "#     else:\n",
    "#         #Working on previous loans where the numbers are important\n",
    "#         proc_df['total_loan_duration'] = proc_df['closeddate'] - proc_df['creationdate']\n",
    "#         proc_df['total_loan_duration'] = proc_df['total_loan_duration'].dt.seconds\n",
    "        \n",
    "#         proc_df['approveddayofweek'] = proc_df['approveddate'].dt.dayofweek\n",
    "#         proc_df['approvedmonth'] = proc_df['approveddate'].dt.month\n",
    "#         proc_df['creationdayofweek'] = proc_df['creationdate'].dt.dayofweek\n",
    "#         proc_df['creationmonth'] = proc_df['creationdate'].dt.month\n",
    "        \n",
    "#     proc_df['is_month_start_approved'] = proc_df['approveddate'].dt.is_month_start\n",
    "#     proc_df['is_month_end_approved'] = proc_df['approveddate'].dt.is_month_end\n",
    "#     proc_df['is_month_start_creation'] = proc_df['creationdate'].dt.is_month_start\n",
    "#     proc_df['is_month_end_creation'] = proc_df['creationdate'].dt.is_month_end\n",
    "    \n",
    "#     #Get the approval time elapsed in seconds\n",
    "#     proc_df['loan_approval_time_elapsed'] = proc_df['approveddate'] - proc_df['creationdate']\n",
    "#     proc_df['loan_approval_time_elapsed'] = proc_df['loan_approval_time_elapsed'].dt.seconds\n",
    "    \n",
    "    #Drop the date columns\n",
    "    proc_df.drop(['creationdate','approveddate'], axis=1, inplace=True)\n",
    "    \n",
    "    if dataset == 'train':\n",
    "        #Convert the target column to boolean values: 0 ===> Good, 1 ==>Bad\n",
    "        dict_target = {\"Good\": 1, \"Bad\": 0}\n",
    "        target = proc_df['good_bad_flag'].map(dict_target)\n",
    "        proc_df.drop(['good_bad_flag'], axis=1, inplace=True)\n",
    "        return (proc_df, target)\n",
    "    else:\n",
    "        return proc_df\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3798fd7f876da111336c8153deeb7dfc14f86341"
   },
   "outputs": [],
   "source": [
    "new_trainperf,target = process_perf_data(trainperf)\n",
    "new_testperf = process_perf_data(testperf, dataset='test')\n",
    "new_trainperf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9afa263a6db7a6347f298a23f9aa4c2bd534e8e7"
   },
   "outputs": [],
   "source": [
    "new_testperf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3f8f0997fca1dfa4dfbbf9011bca9f212298cac"
   },
   "outputs": [],
   "source": [
    "def get_percent_of_missing(df):\n",
    "    missing = (df.isnull().sum() / len(df)) * 100\n",
    "    missing = missing.drop(missing[missing == 0].index).sort_values(ascending=False)\n",
    "    missing_data = pd.DataFrame({'Missing Ratio' :missing})\n",
    "    print(missing_data)\n",
    "    return\n",
    "\n",
    "def align_dataframes(train,test):\n",
    "    # Align the training and testing data. This is done because of the onehot encoding which \n",
    "    # introduces extra columns into the train data. We keep only columns present in both dataframes\n",
    "    train, test = train.align(test, join = 'inner', axis = 1)\n",
    "    return (train,test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c59f46f53984acdc5db6789e399ca9efa80ce489"
   },
   "outputs": [],
   "source": [
    "get_percent_of_missing(new_trainperf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c08968103c6f0962b71fd77aefc1daa3219d72cf"
   },
   "outputs": [],
   "source": [
    "get_percent_of_missing(new_testperf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f40dac2614410839ec8b0b31eade784f59c825bf"
   },
   "outputs": [],
   "source": [
    "# #Correlation map to see how features are correlated with SalePrice\n",
    "# corrmat = new_trainperf.corr()\n",
    "# plt.subplots(figsize=(10,8))\n",
    "# sns.heatmap(corrmat, vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "872b34d5765bce98dc72845627d9ea17f8b2ae24"
   },
   "outputs": [],
   "source": [
    "#Drop the ID columns\n",
    "new_trainperf.drop(['systemloanid'], axis=1, inplace=True)\n",
    "new_testperf.drop(['systemloanid'], axis=1, inplace=True)\n",
    "\n",
    "# X = pd.get_dummies(new_trainperf.drop(['customerid'], axis=1, inplace=False))\n",
    "# print('New shape of trainperf is', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8aadc669852dcbcc9f4915e5472400c0b50af98"
   },
   "outputs": [],
   "source": [
    "#Let's look the target variable\n",
    "target.astype(int).plot.hist()\n",
    "#We can see that we have an inbalance class problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0dca5b4eee1729afbed25dab54253642edded716"
   },
   "source": [
    "Now, Let's look at the other data, starting with the previous loan data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "90a003169f7476909b0db8b188459e6831abbd1f"
   },
   "outputs": [],
   "source": [
    "trainprevloans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba6667590b1ebb55fc52a37c7a88c06587a33959"
   },
   "source": [
    "**Most of the columns are similar to the train performance data. So we can use the same function as earlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2eb81631c725faa4cbc41aaf5144366260b3711a"
   },
   "outputs": [],
   "source": [
    "new_trainprev = process_perf_data(trainprevloans, dataset='none', to_categorical=False)\n",
    "new_testprev = process_perf_data(testprevloans, dataset='none', to_categorical=False)\n",
    "new_trainprev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8517054907c2411453fa070f32c125ad313135a"
   },
   "outputs": [],
   "source": [
    "new_testprev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c147466839cc006f2da4ba1d61e2a463aca6a74e"
   },
   "source": [
    "**Let's create a function to clean the remaining columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2faed0fac73ad76991dd0f56ba85a2daca2eec9a"
   },
   "outputs": [],
   "source": [
    "def process_prevloans(df):\n",
    "    df = df.copy()\n",
    "    df['diff_due_and_repay'] = df['firstrepaiddate'] - df['firstduedate']\n",
    "    df['diff_due_and_repay'] = df['diff_due_and_repay'].dt.seconds\n",
    "    \n",
    "    df['diff_closed_and_due'] = df['closeddate'] - df['firstduedate']\n",
    "    df['diff_closed_and_due'] = df['diff_closed_and_due'].dt.seconds\n",
    "    \n",
    "    df['due_dayofweek'] = df['firstduedate'].dt.dayofweek\n",
    "    df['due_month'] = df['firstduedate'].dt.month\n",
    "    \n",
    "    df['repaid_dayofweek'] = df['firstrepaiddate'].dt.dayofweek\n",
    "    df['repaid_month'] = df['firstrepaiddate'].dt.month\n",
    "    \n",
    "    df['is_month_start_repaid'] = df['firstrepaiddate'].dt.is_month_start\n",
    "    df['is_month_end_repaid'] = df['firstrepaiddate'].dt.is_month_end\n",
    "    \n",
    "    df['is_month_start_duedate'] = df['firstduedate'].dt.is_month_start\n",
    "    df['is_month_end_duedate'] = df['firstduedate'].dt.is_month_end\n",
    "    \n",
    "    #DRop old date columns\n",
    "    df.drop(['closeddate','firstduedate','firstrepaiddate'],axis=1,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b861b6b249eb2a0aec19393ae8e28f1262992dae"
   },
   "outputs": [],
   "source": [
    "new_trainprev = process_prevloans(new_trainprev)\n",
    "new_testprev = process_prevloans(new_testprev)\n",
    "print('Shape of new_trainprev:', new_trainprev.shape)\n",
    "print('Shape of new_testprev:', new_testprev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts_df = new_trainprev.groupby('customerid', as_index=False)['systemloanid'].count()\n",
    "# new_trainperf['prev_loan_count'] = counts_df['systemloanid']\n",
    "# #DO FOR TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26913d60d668d85ed0d64bfc202eddd600a81d8a"
   },
   "outputs": [],
   "source": [
    "def merge_2_df(df1,df2):\n",
    "    # Join two dataframe\n",
    "    df = df1.merge(df2, how='left',on='customerid')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ffdc310474aac0d95b46dfff94bdd35272da45b"
   },
   "outputs": [],
   "source": [
    "def calculate_agg(df):\n",
    "    # Group by the customer id, calculate aggregation statistics\n",
    "    df_agg = df.drop(columns = ['systemloanid']).groupby('customerid', as_index = False).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
    "    # List to hold column names\n",
    "    columns = ['customerid']\n",
    "    # Iterate through the variables names\n",
    "    for var in df_agg.columns.levels[0]:\n",
    "        # Skip the id name\n",
    "        if var != 'customerid':      \n",
    "            # Iterate through the calculated stat names\n",
    "            for stat in df_agg.columns.levels[1][:-1]:\n",
    "                # Make a new column name for the variable and stat\n",
    "                columns.append('prevloan_%s_%s' % (var, stat))\n",
    "    \n",
    "    # Assign the list of columns names as the dataframe column names\n",
    "    df_agg.columns = columns\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ada431ee4a6185a17906027c952048ca7f42c1a"
   },
   "outputs": [],
   "source": [
    "train_2_merge = calculate_agg(new_trainprev)\n",
    "test_2_merge = calculate_agg(new_testprev)\n",
    "\n",
    "new_X = merge_2_df(new_trainperf,train_2_merge)\n",
    "test = merge_2_df(new_testperf,test_2_merge)\n",
    "\n",
    "merged_data = new_X.copy()\n",
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c437b818d4ad918b4a606d5e15f64bcfe6b77a66"
   },
   "outputs": [],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cb94e657abdaf569c7b08a8d4c2f8ba329c8222"
   },
   "source": [
    "**Let's add the final dataset Train demographics**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fac71cbea5a1a10f7be79f6e068d21a7093d144b"
   },
   "outputs": [],
   "source": [
    "traindemographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79099b89ea0da6d7744eb3a5d8a58ce7fba7a708"
   },
   "outputs": [],
   "source": [
    "get_percent_of_missing(traindemographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be2d52ca1a47ee370598b009103e68b942265db1"
   },
   "outputs": [],
   "source": [
    "# traindemographics['employment_status_clients'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15df23c9f175781aa472509408c592b0fdfe6f5e"
   },
   "outputs": [],
   "source": [
    "def process_demographics(df):\n",
    "    proc_df = df.copy()\n",
    "    #Let's extract info from the birthdate\n",
    "    proc_df['customers_age'] = 2018 - proc_df['birthdate'].dt.year\n",
    "    #We'll drop the bank_branch_clients and level_of_education_clients because they contain too many missing values\n",
    "    proc_df.drop(['level_of_education_clients','bank_branch_clients','birthdate'], axis=1, inplace=True)\n",
    "    return proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "017da5fb1156cf53cee632bb83b2665b42129ebd"
   },
   "outputs": [],
   "source": [
    "new_traindemo = process_demographics(traindemographics)\n",
    "new_test = process_demographics(testdemographics)\n",
    "\n",
    "new_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "015eb5d30a6512e2a3f575e41a729e2902dec48c"
   },
   "outputs": [],
   "source": [
    "merged_data = merged_data.drop_duplicates('customerid')\n",
    "test = test.drop_duplicates('customerid')\n",
    "new_traindemo = new_traindemo.drop_duplicates('customerid')\n",
    "new_test = new_test.drop_duplicates('customerid')\n",
    "\n",
    "final_data = merge_2_df(merged_data,new_traindemo)\n",
    "final_test = merge_2_df(test,new_test)\n",
    "\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "913f00f951e4fd13d393e0f9b0a7bba2580c2128"
   },
   "outputs": [],
   "source": [
    "final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d3d249e3173973f3a5a4c63644bd7baaeb5eb04"
   },
   "outputs": [],
   "source": [
    "final_data = pd.get_dummies(final_data)\n",
    "final_test = pd.get_dummies(final_test)\n",
    "\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a491a9dceeccb2f435c03a370e59259c14e988f3"
   },
   "outputs": [],
   "source": [
    "#Align dataset\n",
    "final_train, final_test = final_data.align(final_test, join = 'inner', axis = 1)\n",
    "print(\"Shape of final train is:\", final_train.shape)\n",
    "print(\"Shape of final test is:\", final_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49504289e706c472488280c5c78684277bd58a76"
   },
   "outputs": [],
   "source": [
    "# train_2_save = final_train\n",
    "# train_2_save['target'] = target\n",
    "# train_2_save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd9c1d6ce590941bba67542f200a558927649446"
   },
   "outputs": [],
   "source": [
    "# train_2_save.to_csv(\"DSN_loan_default_ensemble_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_acc(ground_truth,predictions):\n",
    "    acc = accuracy_score(ground_truth, predictions)\n",
    "    return acc\n",
    "\n",
    "def sc_f1(ground_truth,predictions):\n",
    "    acc = f1_score(ground_truth, predictions)\n",
    "    return acc\n",
    "\n",
    "def sc_prec(ground_truth,predictions):\n",
    "    acc = precision_score(ground_truth, predictions)\n",
    "    return acc\n",
    "\n",
    "def sc_recall(ground_truth,predictions):\n",
    "    acc = recall_score(ground_truth, predictions)\n",
    "    return acc\n",
    "\n",
    "def confusion(ground_truth,predictions):\n",
    "    acc = confusion_matrix(ground_truth, predictions)\n",
    "    return acc\n",
    "\n",
    "funcs = [sc_acc, sc_f1, sc_prec, sc_recall]\n",
    "\n",
    "\n",
    "def cross_val(model, data, label):\n",
    "    sf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42).get_n_splits(data)\n",
    "    met = cross_val_score(model, data, label, scoring= custom_scorer, cv = sf)\n",
    "    return np.mean(met) #Remove negative sign\n",
    "\n",
    "\n",
    "def plot_importance(df):\n",
    "    #Sort values by index\n",
    "    df = df.sort_values('importance', ascending = False).reset_index()\n",
    "    #Normalize between 0 and 1\n",
    "    df['importance'] = df['importance'] / df['importance'].sum()\n",
    "    # Make a horizontal bar chart of feature importances\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    ax = plt.subplot()\n",
    "    # Need to reverse the index to plot most important on top\n",
    "    ax.barh(list(reversed(list(df.index[:10]))), \n",
    "            df['importance'].head(10), \n",
    "            align = 'center', edgecolor = 'k')\n",
    "    \n",
    "    # Set the yticks and labels\n",
    "    ax.set_yticks(list(reversed(list(df.index[:10]))))\n",
    "    ax.set_yticklabels(df['feature'].head(10))\n",
    "    # Plot labeling\n",
    "    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n",
    "    plt.savefig('importance.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_lgb ={'num_leaves': [40,50,60], \n",
    "#             'max_depth':  [5,6,7], \n",
    "#             'learning_rate':  [0.01, 0.1, 0.002], \n",
    "#              'colsample_bytree':  [0.5,0.8, 1], \n",
    "#              'min_child_weight': [1e-5, 1e-3, 1e-2 ],\n",
    "#              'reg_alpha': [0, 1e-1, 0.6],\n",
    "#              'reg_lambda': [0, 1e-1, 1],\n",
    "#             'subsample': [0.5,0.8,1],\n",
    "#                'n_estimators': [2000,3000,5000]}\n",
    "\n",
    "# gs = GridSearchCV(xgb_model, param_lgb, cv=5)\n",
    "          \n",
    "\n",
    "# gs.fit(final_train,target)\n",
    "# print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(n_estimators=3000, \n",
    "                              learning_rate=0.01,\n",
    "                              reg_alphe=0.6,\n",
    "                              subsample=0.8,\n",
    "                              max_depth=3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c14acf9de941ee4ee63cbcc825a08e4a0318a402"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_train, target, test_size=0.2)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.model.train_classifier(X_train, y_train,estimator=xgb_model, cross_validate=True, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred, val_label):\n",
    "    acc = accuracy_score(val_label, pred)\n",
    "    f1 = f1_score(val_label, pred)\n",
    "    precision = precision_score(val_label, pred)\n",
    "    recall = recall_score(val_label, pred)\n",
    "    confusion_mat = confusion_matrix(val_label, pred)\n",
    "    \n",
    "    print(\"Accuracy is \", round(acc * 100))\n",
    "    print(\"F1 score is \", round(f1 * 100))\n",
    "    print(\"Precision is \", round(precision * 100))\n",
    "    print(\"Recall is \", round(recall * 100))\n",
    "    print(\"confusion Matrix is \", confusion_mat)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(val_label, pred)\n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    # show the plot\n",
    "    plt.title(\"roc curve for the model\")\n",
    "    plt.show()\n",
    "    plt.savefig(\"roc_plot.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.model.plot_auc(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = final_train.columns\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feat_import = pd.DataFrame({'feature': cols, 'importance': importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(feat_import)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
